---
title: "vignette-images"
Author: David Pan, James San, Peter Xiong, Amy Ji
format: html
editor: visual
---

# Image Classification with CNN

## Data

Worldwide 300,000 people are diagnosed with brain tumors annually with nearly one-third of these cases being cancerous. These characteristics immediately make brain tumors a pressing issue, however brain tumors are very diverse thus would require extensive scans to diagnose specific brain tumor types. This is where image classification comes in, specifically we will be applying a convolutional neural network model. A CNN model strengths lie in it's ability to identify patterns in images and extract features from data which is great for identifying specific brain tumors. In our case, we will be dealing with the three most common types, glioma, meningioma, and pituitary tumors as well as no tumor cases. The data set we will be using contains 7023 MRI images all classified in one of the four classes. With the use of artificial intelligence it could lead to faster detections, personalized treatments, and improved planning.

```{r}
# packages
library(tidyverse)
library(tensorflow)
library(keras3)

tensorflow::set_random_seed(197)

# the data has already been partitioned
batch_size <- 32
img_height <- 256
img_width <- 256

train_tumor <- image_dataset_from_directory(
  directory = 'data/Training',
  image_size = c(img_height, img_width),
  batch_size = batch_size,
  seed = 197
)

test_tumor <- image_dataset_from_directory(
  directory = 'data/Testing',
  image_size = c(img_height, img_width),
  batch_size = batch_size,
  seed = 197
)
```

## Visualize Data

Examine a batch of 32 images.

```{r}
batch <- train_tumor %>% as_iterator() %>% iter_next()

str(batch)
```

The first tensor contains image data. In this batch, there are 32 images that are 256 pixels high and 256 pixels wide. Each pixel is represented as a 3-element vector containing the RGB value associated with the pixel.

The second tensor includes the labels for each image.

```{r}
images <- batch[[1]]
labels <- batch[[2]]

display_image <- function(x, max = 255, margins = c(0,0,0,0)) {
  x %>%
    as.array() %>%
    drop() %>%
    as.raster(max = max) %>%
    plot(interpolate = FALSE)
}

par(mfrow = c(4,8), mar = c(1,1,1,1))
for (i in 1:32){
  display_image(images[i,,,])
}
```

### What is glioma?

Glioma is a type of brain tumor that originates from glial cells in the spinal cord and brain, it is the most common cancerous brain tumor and makes up one-third of all brain tumors.

```{r}
display_image(images[1,,,])
```

### What is meningioma?

A type of brain tumor that grows in the membrane that cover the brain and spinal cord, it is the most common tumor type in the head but are usually non-cancerous, 10-15% are cancerous.

```{r}
display_image(images[13,,,])
```

### What is a pituitary tumor?

The pituitary is a small gland found at the base of the brain, directly in line with the top of your nose. They account for 10-15% of all brain tumors and most are non-cancerous, causing no symptoms. Rarely is it cancerous, less than 0.1%.

```{r}
display_image(images[32,,,])
```

### Non-Tumor

The data set also contains images of non-tumor brains.

```{r}
display_image(images[30,,,])
```

## Single Layer Model

First we test out the most basic neural network, which includes just a single layer. Since the data is a 3 dimensional matrix of numbers, we need to flatten it into a single dimension before feeding it into the model.

### Define model architecture

```{r}
model_single_layer <- keras_model_sequential(input_shape = c(img_height, img_width, 3)) %>%
  layer_rescaling(1./255) %>%
  layer_flatten() %>%
  layer_dense(4) %>%
  layer_activation(activation = 'softmax')

summary(model_single_layer)
```

### Compile model

The adam optimizer is good for general use neural network training, so it should work for our model. The crossentropy loss function is typically used for classification problems, and the neural network's objective is to minimize the value of this function. The optimizer will use the loss function's gradient to try to find the lowest point. Finally, we use accuracy to judge the effectiveness of the model, which is simply the number of correct predictions divided by the number of total predictions.

```{r}
model_single_layer %>% compile(
  optimizer = 'adam',
  loss = 'crossentropy',
  metrics = 'accuracy'
)
```

### Train model

```{r}
history_single_layer <- model_single_layer %>%
  fit(train_tumor, epochs = 20)
```

### Test model

```{r}
evaluate(model_single_layer, test_tumor)
```

This accuracy is not bad for a single layer model, but there is a lot of room for improvement. The testing accuracy is lower than our training accuracy, which is a sign that the model is overfitting the training data.

## Data Augmentation

Data augmentation is a technique often used to reduce overfitting. It involves making alterations to the training data, such as random rotations and flipping, to generate new training data and make the model more robust to unseen data. Here, we will augment the data using changes to brightness and contrast of the training images.

```{r}
# create data augmentation layer
data_augmentation <- keras_model_sequential(input_shape = c(256, 256, 3)) %>%
  layer_random_brightness(factor = 0.1) %>%
  layer_random_contrast(factor = 0.15)

# visualizae changes
par(mfrow = c(3,3), mar = c(1,1,1,1))
for (i in 1:9){
  images[1,,,, drop = FALSE] %>%
    data_augmentation() %>%
    display_image()
}
```

### Update single layer model

```{r}
model_aug <- keras_model_sequential(input_shape = c(img_height, img_width, 3)) %>%
  layer_random_brightness(factor = 0.1) %>%
  layer_random_contrast(factor = 0.15) %>%
  layer_rescaling(1./255) %>%
  layer_flatten() %>%
  layer_dense(4) %>%
  layer_activation(activation = 'softmax')

summary(model_aug)
```

### Compile model

```{r}
model_aug %>% compile(
  optimizer = 'adam',
  loss = 'crossentropy',
  metrics = 'accuracy'
)
```

### Train model

```{r}
history_aug <- model_aug %>%
  fit(train_tumor, epochs = 20)
```

### Test model

```{r}
evaluate(model_aug, test_tumor)
```

Data augmentation provides a boost in testing accuracy due to reduced overfitting.

## Multi Layer Model

Simplified version of the VGG-16 model architecture.

Explanation of what the different types of layers do:

convolutional 2d layer: Extracts features from the image, which is specified by the number of filters. Padding adds pixels around the image to ensure that the input size and output size are matching.

max pooling layer: Takes the maximum value from each 2x2 grid of pixels. This reduces the dimensionality and makes the model more robust to small changes.

dropout layer: Randomly assigns inputs to 0, which reduces overfitting and allows the model to generalize to new data.

dense layer: Typically at the end of model, connects each neuron to the output layer in order to make the final prediction. We used the softmax activation function since there are multiple classes.

```{r}
model_vgg16 <- keras_model_sequential(input_shape = c(256, 256, 3)) %>%
  # Preprocessing layers
  layer_random_brightness(factor = 0.1) %>%
  layer_random_contrast(factor = 0.15) %>%
  layer_rescaling(1./255) %>%
  
  # Convolutional layers
  layer_conv_2d(filters = 8, kernel_size = c(3,3), activation = 'relu', padding = 'same') %>%
  layer_max_pooling_2d(pool_size = c(2,2), strides = c(2,2)) %>%
  
  layer_conv_2d(filters = 16, kernel_size = c(3,3), activation = 'relu', padding = 'same') %>%
  layer_max_pooling_2d(pool_size = c(2,2), strides = c(2,2)) %>%
  
  layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = 'relu', padding = 'same') %>%
  layer_max_pooling_2d(pool_size = c(2,2), strides = c(2,2)) %>%
  
  layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = 'relu', padding = 'same') %>%
  layer_max_pooling_2d(pool_size = c(2,2), strides = c(2,2)) %>%
  
  layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = 'relu', padding = 'same') %>%
  layer_max_pooling_2d(pool_size = c(2,2), strides = c(2,2)) %>%
  
  # Fully connected layers
  layer_flatten() %>%
  layer_dense(units = 4096, activation = 'relu') %>%
  layer_dropout(rate = 0.5) %>%
  layer_dense(units = 4, activation = 'softmax')

summary(model_vgg16)
```

## Compile model

```{r}
model_vgg16 %>% compile(loss = 'crossentropy',
                  optimizer = 'adam',
                  metrics = 'accuracy')
```

## Train model

```{r}
history_vgg16 <- model_vgg16 %>%
  fit(train_tumor, epochs = 10)
```

## Test model

```{r}
evaluate(model_vgg16, test_tumor)
```
